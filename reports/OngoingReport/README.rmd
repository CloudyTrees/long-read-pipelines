---
title: "README"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(magrittr)
library(ggplot2)
library(curl)
library(rjson)
library(vcfR)
```

```{r gcs_timestamp}
gcs_timestamp <- function(x) {
   return(unlist(strsplit(system(paste("/Users/kiran/google-cloud-sdk/bin/gsutil ls -l", x), intern=TRUE)[1], "\\s+", perl=TRUE))[3])
}
```

```{r gs_cat}
gs_cat <- function(file, pipe="") {
    return(system(paste("/Users/kiran/google-cloud-sdk/bin/gsutil cat", file, ifelse(pipe == "", "", "|"), pipe), intern=TRUE))
}
```

```{r gs_ls}
gs_ls <- function(file) {
    as = system(paste("/Users/kiran/google-cloud-sdk/bin/gsutil ls -l", file), intern=TRUE, ignore.stderr=TRUE)
    
    ll = list()
    index = 1
    if (length(as) == 0) {
        ll[[index]] = list(size = 0, timestamp = "", "file" = file)
    } else {
        for (a in as[1:length(as)-1]) {
            l = unlist(strsplit(gsub("^\\s+", "", a), "\\s+", perl=TRUE))
            s = as.numeric(l[1])
            dt = parse_datetime(l[2])
            f = l[3]
            
            ll[[index]] = list(size = s, timestamp = dt, file = f)
            index = index + 1
        }
    }
    
    return(ll)
}
```

```{r gs_best}
gs_best <- function(ll) {
    l = ll[[which.max(unlist(lapply(ll, function(x) { return(x$size); })))]]
    
    return(l)
}
```

```{r gs_exists}
gs_exists <- function(file) {
    f = gs_best(gs_ls(file))
    
    return(f$size > 0)
}
```

```{r gs_read_table}
gs_read_table <- function(table_file) {
    q = gs_cat(table_file)
    qa = grep("#|^$", q, value=TRUE, invert=TRUE)
    f = read.table(textConnection(qa), sep="\t", header=TRUE)
    
    return(as_tibble(f))
}
```

```{r get_splitsubreads_stats}
get_splitsubreads_stats <- function(cromwell_hash) {
    l = gs_best(gs_ls(paste("gs://broad-dsde-methods-kiran/workflow_output/CorrectAndAlignWorkflow/", cromwell_hash, "/call-SplitSubreads/**SplitSubreads.log", sep="")))
    
    if (gs_exists(l$file)) {
        sslog = l$file
        timestamp = l$timestamp
        cmd = gs_cat(paste(sslog, "| grep -m1 java"))
        codec = ifelse(grep("jdk-deflater", cmd), "JDK", "Intel")
        
        compression = 2;
        if (grepl("compression", cmd)) {
            compression = unlist(strsplit(grep("compression", unlist(strsplit(cmd, " ")), value=TRUE), "="))[2]
        }
        
        approx_reads_per_shard = unlist(strsplit(cmd, " "))[grep("-nr", unlist(strsplit(cmd, " "))) + 1]
        movie_name = gsub(".subreads.bam", "", basename(grep(".subreads.bam", unlist(strsplit(cmd, " ")), value=TRUE)))
        sample_name = basename(dirname(grep(".subreads.bam", unlist(strsplit(cmd, " ")), value=TRUE)))
        if (sample_name == "1_A01" || sample_name == "3_C01") {
            sample_name = basename(dirname(dirname(grep(".subreads.bam", unlist(strsplit(cmd, " ")), value=TRUE))))
        }
        
        q = gs_cat(sslog, "grep '.bam'") %>% tail(n=1) %>% strsplit("[.\\s]+", perl=TRUE) %>% unlist()
        num_shards = as.integer(q[length(q)-1])
        
        return(list(timestamp = timestamp,
                    codec = codec,
                    compression = as.integer(compression),
                    approx_reads_per_shard = as.integer(approx_reads_per_shard),
                    movie_name = movie_name,
                    sample_name = sample_name,
                    num_shards = num_shards)
               )
    } else {
        return(list(timestamp = 0,
                    codec = "none",
                    compression = 0,
                    approx_reads_per_shard = 0,
                    movie_name = "none",
                    sample_name = "none",
                    num_shards = 0)
               )
    }
}
```

```{r get_ccs_report}
get_ccs_report <- function(cromwell_hash) {
    x = paste("gs://broad-dsde-methods-kiran/workflow_output/CorrectAndAlignWorkflow/", cromwell_hash, "/call-MergeCCSReports/**ccs_report.txt", sep="")
    xa = gs_best(gs_ls(x))
    
    report = list()
    if (gs_exists(xa$file)) {
        ls = gs_cat(xa$file)
        
        for (l in ls) {
            if (grepl("Success|Failed", l)) {
                q = gsub(" ", "_", tolower(unlist(strsplit(l, "\\s+--\\s+|,|%", perl=TRUE))))
                report[paste(q[1], q[2], sep="_")] = as.integer(q[3])
            }
        }
    } else {
        report = list(
            "success_(without_retry)_ccs_generated" = 0,
            "success_(with_retry)_ccs_generated" = 0,
            "failed_below_snr_threshold" = 0,
            "failed_no_usable_subreads" = 0,
            "failed_insert_size_too_long" = 0,
            "failed_insert_size_too_small" = 0,
            "failed_not_enough_full_passes" = 0,
            "failed_too_many_unusable_subreads" = 0,
            "failed_ccs_did_not_converge" = 0,
            "failed_ccs_below_minimum_predicted_accuracy" = 0,
            "failed_unknown_error_during_processing" = 0
        )
    }
    
    return(report)
}
```

```{r get_read_lengths_file}
get_read_lengths_file <- function(cromwell_hash) {
    rlfile = paste("gs://broad-dsde-methods-kiran/workflow_output/CorrectAndAlignWorkflow/", cromwell_hash, "/call-ReadLengthsCorrected/**.readlengths.txt", sep="")
    rl = gs_ls(rlfile)
    return(gs_best(rl))
}
```

```{r get_workflow_execution_status}
get_workflow_execution_status <- function(cromwell_hash) {
    return(fromJSON(readLines(curl(paste("https://cromwell-v36.dsde-methods.broadinstitute.org/api/workflows/v1/", cromwell_hash, "/status", sep="")), warn=FALSE))$status)
}
```

```{r get_bam_uncorrected_file}
get_bam_uncorrected_file <- function(cromwell_hash) {
    bam_file = paste("gs://broad-dsde-methods-kiran/workflow_output/CorrectAndAlignWorkflow/", cromwell_hash, "/call-MergeUncorrected/**.bam", sep="")
    return(gs_best(gs_ls(bam_file)))
}
```

```{r get_bam_corrected_file}
get_bam_corrected_file <- function(cromwell_hash) {
    bam_file = paste("gs://broad-dsde-methods-kiran/workflow_output/CorrectAndAlignWorkflow/", cromwell_hash, "/call-MergeCorrected/**.bam", sep="")
    return(gs_best(gs_ls(bam_file)))
}
```

```{r get_bam_remaining_file}
get_bam_remaining_file <- function(cromwell_hash) {
    bam_file = paste("gs://broad-dsde-methods-kiran/workflow_output/CorrectAndAlignWorkflow/", cromwell_hash, "/call-MergeRemaining/**.bam", sep="")
    return(gs_best(gs_ls(bam_file)))
}
```

```{r get_alignment_stats}
get_alignment_stats <- function(cromwell_hash, type) {
    tbl_file = paste("gs://broad-dsde-methods-kiran/workflow_output/CorrectAndAlignWorkflow/", cromwell_hash, "/call-AlignmentStats", type, "/**.alignment.report.txt", sep="")
    
    tbl = gs_best(gs_ls(tbl_file))
    
    if (gs_exists(tbl$file)) {
        return(gs_read_table(tbl$file))
    }
    
    am = tribble(
~CATEGORY, ~TOTAL_READS, ~PF_READS, ~PCT_PF_READS, ~PF_NOISE_READS,  ~PF_READS_ALIGNED, ~PCT_PF_READS_ALIGNED, ~PF_ALIGNED_BASES, ~PF_HQ_ALIGNED_READS, ~PF_HQ_ALIGNED_BASES, ~PF_HQ_ALIGNED_Q20_BASES, ~PF_HQ_MEDIAN_MISMATCHES, ~PF_MISMATCH_RATE, ~PF_HQ_ERROR_RATE, ~PF_INDEL_RATE, ~MEAN_READ_LENGTH, ~READS_ALIGNED_IN_PAIRS, ~PCT_READS_ALIGNED_IN_PAIRS, ~PF_READS_IMPROPER_PAIRS, ~PCT_PF_READS_IMPROPER_PAIRS, ~BAD_CYCLES, ~STRAND_BALANCE, ~PCT_CHIMERAS, ~PCT_ADAPTER, ~SAMPLE, ~LIBRARY, ~READ_GROUP,
"UNPAIRED", 0,            0,         0,             0,                0,                 0.0,                   0,                 0,                                        0,                    0,                        0,                       0.0,                0.0,               0.0,            0.0,               0,                       0,                           0,                        0,                            0,           0.0,             0.0,           0,            FALSE,   FALSE,             FALSE
    )
    
    return(am)
}
```

```{r get_workflow_stats}
get_workflow_stats <- function(cromwell_hash) {
    splitsubreads_stats = get_splitsubreads_stats(cromwell_hash)
    ccs_stats = get_ccs_report(cromwell_hash)
    rl_file = get_read_lengths_file(cromwell_hash)
    
    bam_uncorrected_file = get_bam_uncorrected_file(cromwell_hash)
    bam_corrected_file = get_bam_corrected_file(cromwell_hash)
    bam_remaining_file = get_bam_remaining_file(cromwell_hash)
    
    alignment_stats_uncorrected = get_alignment_stats(cromwell_hash, "Uncorrected")
    alignment_stats_corrected = get_alignment_stats(cromwell_hash, "Corrected")
    alignment_stats_remaining = get_alignment_stats(cromwell_hash, "Remaining")
    
    return(c(list("cromwell_hash" = cromwell_hash),
             workflow_status = get_workflow_execution_status(cromwell_hash),
             splitsubreads_stats,
             ccs_stats,
             file_read_lengths_path = rl_file$file,
             file_read_lengths_size = rl_file$size,
             file_bam_corrected_file = bam_corrected_file$file,
             file_bam_corrected_size = bam_corrected_file$size,
             file_bam_uncorrected_file = bam_uncorrected_file$file,
             file_bam_uncorrected_size = bam_uncorrected_file$size,
             file_bam_remaining_file = bam_remaining_file$file,
             file_bam_remaining_size = bam_remaining_file$size
             )
           )
}
```

```{r sample_status}
samples_tbl = tribble(
~sample,	     ~rel_to_proband, ~sex,      ~pop,
"Ecoli",         NA,              NA,        NA,
"NA12891",       "father",        "male",    "CEU",
"NA12892",       "mother",        "female",  "CEU",
"NA12878rep1",   "proband",       "female",  "CEU",
"NA12878rep2",   "proband",       "female",  "CEU",
"HG02982",       "father",        "male",    "GWD",
"HG02983",       "mother",        "female",  "GWD",
"HG02984",       "proband",       "male",    "GWD",
"HG00512",       "father",        "male",    "CHS",
"HG00513",       "mother",        "female",  "CHS",
"HG00514",       "proband",       "female",  "CHS",
"NA19239",       "father",        "male",    "YRI",
"NA19238",       "mother",        "female",  "YRI",
"NA19240",       "proband",       "female",  "YRI",
"HG00731",       "father",        "male",    "PUR",
"HG00732",       "mother",        "female",  "PUR",
"HG00733",       "proband",       "female",  "PUR",
"SM-GNXIC",      "mother",        "female",  "?",
"SM-GNXID",      "father",        "male",    "?",
"SM-GM5IP",      "proband",       "female",  "?",
"VS_ABC012_3_1", "mother",        "female",  "?",
"VS_ABC012_1_1", "proband",       "unknown", "?",
"VS_ABC012_2_1", "father",        "male",    "?"
)

a = system("/Users/kiran/google-cloud-sdk/bin/gsutil ls gs://broad-dsde-methods-kiran/pb_eap/", intern=TRUE);
buckets = grep("SmallTestData", a[2:length(a)], invert=TRUE, value=TRUE, perl=TRUE) %>% sort()

samples_tbl$run_type = NA
samples_tbl$bucket = NA

for (bucket in buckets) {
    for (sample in samples_tbl$sample) {
        if (grepl(sample, bucket) || grepl(gsub("NA19", "NA129", sample), bucket)) {
            samples_tbl[which(samples_tbl$sample == sample), "bucket"] = bucket
            samples_tbl[which(samples_tbl$sample == sample), "run_type"] = ifelse(grepl("_CLR", bucket), "CLR", "CCS")
        }
    }
}
```


```{r cromwell_hashes}
cromwell_hashes = c(
    "dfad1c6c-246d-43dc-af36-17a7d5712a3a",
    "16884faf-2359-47d4-817f-03d2e0561540",
    "96cf0495-fdd3-46c0-a5c8-91f4cd19eabb",
    "3c30905a-a7bc-4b96-bb58-52327d8395bf",
    "9f138dee-162c-4eec-8f20-3ba189d393e7",
    "2e54ab02-3924-4918-a86c-160d0993e008",
    "66c72d9b-ccb1-4aa7-a9fd-374e88274e4f",
    "6d49fa15-719b-401b-b4ae-95d6d2c32f0e",
    "def40ee2-d5a4-43f2-84b5-599ac04a6bfc",
    "f5da6cc2-16ef-481a-9aac-224e7f4d0691",
    "2f12f967-6a3d-461b-b26f-3bb9f52c1ec3",
    "b9ea6c00-0ecd-433b-83f0-f4fbcecdb901",
    "ce3a3344-a09f-4c93-9026-945fae03c93a",
    "6c16bf66-975f-4051-a84a-ecee334d407a",
    "3433e4b1-a991-467d-8b42-2ae74852a35b",
    "e8e48f57-c04a-4dfe-bc10-bbac9b783f47",
    "dac336dc-66d5-4790-8879-3d3ce729bc10",
    "19f94ab9-4882-4405-bf9f-7a026b333bf7",
    "d6d814ff-d06d-447d-a38c-60a0204afa08",
    "e13c74a8-8bd4-4ec4-84ae-96cc5e12bf67",
    "35ba136d-73c0-49d6-a00d-ee53f1871300",
    "ba3e29f9-952f-4e10-9ae6-d2747ca663dc",
    "40d481ba-2374-474d-a95b-3b45490e366e"
)
```

```{r selected_progress, warning=FALSE}
all_stats = NULL
for (cromwell_hash in cromwell_hashes) {
    stats = as_tibble(get_workflow_stats(cromwell_hash))
    
    if (is.null(all_stats)) {
        all_stats = stats
    } else {
        all_stats = rbind(all_stats, stats)
    }
    
    print(paste(cromwell_hash, stats$sample_name, stats$timestamp))
}
```

```{r look_at_vcfs}
vcf_files = list(
    NA12878rep1 = "../../m64020_190208_213731.subreads.ccs.aligned.merged.pbsv.vcf",
    NA12878rep2 = "../../m64020_190210_035026.subreads.ccs.aligned.merged.pbsv.vcf",
    NA12891 = "../../m64020_190211_100935.subreads.ccs.aligned.merged.pbsv.vcf",
    NA12892 = "../../m64020_190212_162420.subreads.ccs.aligned.merged.pbsv.vcf"
)

vcfs = list()

samples = "NA12878rep1"
for (sample in names(vcf_files)) {
#for (sample in samples) {
    vcf = vcfR2tidy(read.vcfR(vcf_files[[sample]], verbose=TRUE), format_fields = c("GT", "AD", "DP"))
    
    vcfs[[sample]] = vcf
    
    a = (vcfs[[sample]]$fix %>% select(SVLEN) %>% mutate(SVLEN = as.integer(SVLEN)) %>% filter(!is.na(SVLEN)) %>% range()) + c(-1000, 1000)
    vcfs[[sample]]$fix %>% select(SVLEN) %>%
                           filter(!is.na(SVLEN)) %>%
                           mutate(SVLEN = as.integer(SVLEN)) %>%
                           pull(SVLEN) %>%
                           hist(breaks=seq(ra[1], ra[2], by=10), xlim=c(-1000, 1000), main = paste("SV lengths in", sample), las=2)
    
    labels = vcfs[[sample]]$fix %>% select(SVTYPE) %>% group_by(SVTYPE) %>% count()
    
    for (i in 1:nrow(labels)) {
        text(500, 10000 - (i*800), paste(labels[i,], collapse = ": "), pos=2)
    }
}
```

```{r progress, warning=FALSE}
workflows = system("/Users/kiran/google-cloud-sdk/bin/gsutil ls gs://broad-dsde-methods-kiran/workflow_output/CorrectAndAlignWorkflow/", intern=TRUE)

for (workflow in workflows) {
    cromwell_hash = basename(workflow)
     
    stats = get_workflow_stats(cromwell_hash)
    print(paste(cromwell_hash, stats$sample_name))
}
```

```{r processing_progress, warning=FALSE}
asrs = system("/Users/kiran/google-cloud-sdk/bin/gsutil ls gs://broad-dsde-methods-kiran/workflow_output/CorrectAndAlignWorkflow/*/call-AlignmentStatsCorrected/**report.txt", intern=TRUE)

m = c()

for (asr in asrs) {
    sslog = paste(dirname(dirname(asr)), "/call-SplitSubreads/SplitSubreads.log", sep="")
    
    cmd = system(paste("/Users/kiran/google-cloud-sdk/bin/gsutil cat", sslog, " | grep -m1 java"), intern=TRUE)
    cromwell_hash = basename(dirname(dirname(sslog)))
    codec = ifelse(grep("jdk-deflater", cmd), "JDK", "Intel")
    
    compression = 2;
    if (grepl("compression", cmd)) {
        compression = unlist(strsplit(grep("compression", unlist(strsplit(cmd, " ")), value=TRUE), "="))[2]
    }
    
    approx_reads_per_shard = unlist(strsplit(cmd, " "))[grep("-nr", unlist(strsplit(cmd, " "))) + 1]
    movie_name = gsub(".subreads.bam", "", basename(grep(".subreads.bam", unlist(strsplit(cmd, " ")), value=TRUE)))
    sample_name = basename(dirname(grep(".subreads.bam", unlist(strsplit(cmd, " ")), value=TRUE)))
    if (sample_name == "3_C01") {
        sample_name = basename(dirname(dirname(grep(".subreads.bam", unlist(strsplit(cmd, " ")), value=TRUE))))
    }
    sample_name = gsub("NA129", "NA19", gsub("^\\w\\w\\w_", "", sample_name, perl=TRUE))
    
    merged_uncorrected_bam = paste("gs://broad-dsde-methods-kiran/workflow_output/CorrectAndAlignWorkflow/", cromwell_hash, "/call-MergeUncorrected/", movie_name, ".subreads.aligned.merged.bam", sep="")
    merged_uncorrected_bai = paste("gs://broad-dsde-methods-kiran/workflow_output/CorrectAndAlignWorkflow/", cromwell_hash, "/call-MergeUncorrected/", movie_name, ".subreads.aligned.merged.bai", sep="")
    merged_corrected_bam = paste("gs://broad-dsde-methods-kiran/workflow_output/CorrectAndAlignWorkflow/", cromwell_hash, "/call-MergeCorrected/", movie_name, ".subreads.ccs.aligned.merged.bam", sep="")
    merged_corrected_bai = paste("gs://broad-dsde-methods-kiran/workflow_output/CorrectAndAlignWorkflow/", cromwell_hash, "/call-MergeCorrected/", movie_name, ".subreads.ccs.aligned.merged.bai", sep="")
    merged_remaining_bam = paste("gs://broad-dsde-methods-kiran/workflow_output/CorrectAndAlignWorkflow/", cromwell_hash, "/call-MergeRemaining/", movie_name, ".subreads.ccs.uncorrected.aligned.merged.bam", sep="")
    merged_remaining_bai = paste("gs://broad-dsde-methods-kiran/workflow_output/CorrectAndAlignWorkflow/", cromwell_hash, "/call-MergeRemaining/", movie_name, ".subreads.ccs.uncorrected.aligned.merged.bai", sep="")
    
    merged_uncorrected_size = as.double(system(paste("/Users/kiran/google-cloud-sdk/bin/gsutil ls -lh", merged_uncorrected_bam, "| grep -v TOTAL | awk '{ print $1 }'"), intern=TRUE))
    merged_corrected_size = as.double(system(paste("/Users/kiran/google-cloud-sdk/bin/gsutil ls -lh", merged_corrected_bam, "| grep -v TOTAL | awk '{ print $1 }'"), intern=TRUE))
    merged_remaining_size = as.double(system(paste("/Users/kiran/google-cloud-sdk/bin/gsutil ls -lh", merged_remaining_bam, "| grep -v TOTAL | awk '{ print $1 }'"), intern=TRUE))
    
    merged_uncorrected_size = ifelse(identical(merged_uncorrected_size, numeric(0)), 0, merged_uncorrected_size)
    merged_corrected_size = ifelse(identical(merged_corrected_size, numeric(0)), 0, merged_corrected_size)
    merged_remaining_size = ifelse(identical(merged_remaining_size, numeric(0)), 0, merged_remaining_size)
    
    run_type = ifelse(grepl("_CLR", sample_name), "CLR", "CCS")
    run_date = gcs_timestamp(asr)
    
    depth_uncorrected = unlist(strsplit(system(paste("/Users/kiran/google-cloud-sdk/bin/gsutil cat gs://broad-dsde-methods-kiran/workflow_output/CorrectAndAlignWorkflow/", cromwell_hash, "/call-DepthUncorrected/coverage.txt", sep=""), intern=TRUE), " "))
    depth_uncorrected_mean = as.double(ifelse(is.null(depth_uncorrected), 0, depth_uncorrected[2]))
    depth_uncorrected_sd = as.double(ifelse(is.null(depth_uncorrected), 0, depth_uncorrected[3]))
    depth_uncorrected_median = as.double(ifelse(is.null(depth_uncorrected), 0, depth_uncorrected[4]))
    
    depth_corrected = unlist(strsplit(system(paste("/Users/kiran/google-cloud-sdk/bin/gsutil cat gs://broad-dsde-methods-kiran/workflow_output/CorrectAndAlignWorkflow/", cromwell_hash, "/call-DepthCorrected/coverage.txt", sep=""), intern=TRUE), " "))
    depth_corrected_mean = as.double(ifelse(is.null(depth_corrected), 0, depth_corrected[2]))
    depth_corrected_sd = as.double(ifelse(is.null(depth_corrected), 0, depth_corrected[3]))
    depth_corrected_median = as.double(ifelse(is.null(depth_corrected), 0, depth_corrected[4]))
    
    depth_remaining = unlist(strsplit(system(paste("/Users/kiran/google-cloud-sdk/bin/gsutil cat gs://broad-dsde-methods-kiran/workflow_output/CorrectAndAlignWorkflow/", cromwell_hash, "/call-DepthRemaining/coverage.txt", sep=""), intern=TRUE), " "))
    depth_remaining_mean = as.double(ifelse(is.null(depth_remaining), 0, depth_remaining[2]))
    depth_remaining_sd = as.double(ifelse(is.null(depth_remaining), 0, depth_remaining[3]))
    depth_remaining_median = as.double(ifelse(is.null(depth_remaining), 0, depth_remaining[4]))
    
    ccs_report_gs = paste("gs://broad-dsde-methods-kiran/workflow_output/CorrectAndAlignWorkflow/", cromwell_hash, "/call-MergeCCSReports/ccs_report.txt", sep="")
    ccs = get_ccs_report(ccs_report_gs)
    
    if (length(ccs) == 0) {
        ccs = list(
            "success_(without_retry)_ccs_generated" = 0,
            "success_(with_retry)_ccs_generated" = 0,
            "failed_below_snr_threshold" = 0,
            "failed_no_usable_subreads" = 0,
            "failed_insert_size_too_long" = 0,
            "failed_insert_size_too_small" = 0,
            "failed_not_enough_full_passes" = 0,
            "failed_too_many_unusable_subreads" = 0,
            "failed_ccs_did_not_converge" = 0,
            "failed_ccs_below_minimum_predicted_accuracy" = 0
        )
    }
    
    astats_uncorrected = get_alignment_stats(paste("gs://broad-dsde-methods-kiran/workflow_output/CorrectAndAlignWorkflow/", cromwell_hash, "/call-AlignmentStatsUncorrected/", movie_name, ".subreads.aligned.merged.alignment.report.txt", sep=""))
    astats_corrected = get_alignment_stats(paste("gs://broad-dsde-methods-kiran/workflow_output/CorrectAndAlignWorkflow/", cromwell_hash, "/call-AlignmentStatsCorrected/", movie_name, ".subreads.ccs.aligned.merged.alignment.report.txt", sep=""))
    astats_remaining = get_alignment_stats(paste("gs://broad-dsde-methods-kiran/workflow_output/CorrectAndAlignWorkflow/", cromwell_hash, "/call-AlignmentStatsRemaining/", movie_name, ".subreads.ccs.uncorrected.aligned.merged.alignment.report.txt", sep=""))
    
    #tm$ccs_success_wo_retry_generated + tm$ccs_success_w_retry_generated
    #tm$ccs_failed_below_snr_threshold + tm$ccs_failed_no_usable_subreads + tm$ccs_failed_insert_size_too_long + tm$ccs_failed_insert_size_too_small + tm$ccs_failed_not_enough_full_passes + tm$ccs_failed_not_enough_full_passes + tm$ccs_failed_too_many_unusable_subreads + tm$ccs_failed_did_not_converge + tm$ccs_failed_below_minimum_predicted_accuracy
    
    m = rbind(m, c(run_date, cromwell_hash, codec, compression, approx_reads_per_shard, movie_name, sample_name, run_type, merged_uncorrected_bam, merged_uncorrected_size, depth_uncorrected_mean, depth_uncorrected_sd, depth_uncorrected_median, merged_corrected_bam, merged_corrected_size, depth_corrected_mean, depth_corrected_sd, depth_corrected_median, merged_remaining_bam, merged_remaining_size, depth_remaining_mean, depth_remaining_sd, depth_remaining_median, as.integer(astats_uncorrected$TOTAL_READS[1]), as.integer(astats_corrected$TOTAL_READS[1]), as.integer(astats_remaining$TOTAL_READS[1]), ccs$`success_(without_retry)_ccs_generated`, ccs$`success_(with_retry)_ccs_generated`, ccs$failed_below_snr_threshold, ccs$failed_no_usable_subreads, ccs$failed_insert_size_too_long, ccs$failed_insert_size_too_small, ccs$failed_not_enough_full_passes, ccs$failed_too_many_unusable_subreads, ccs$failed_ccs_did_not_converge, ccs$failed_ccs_below_minimum_predicted_accuracy, ccs$failed_unknown_error_during_processing))
}

colnames(m) = c("run_date", "cromwell_hash", "codec", "compression", "shard_size", "movie_name", "sample_name", "run_type", "merged_uncorrected_bam", "merged_uncorrected_size", "depth_uncorrected_mean", "depth_uncorrected_sd", "depth_uncorrected_median", "merged_corrected_bam", "merged_corrected_size", "depth_corrected_mean", "depth_corrected_sd", "depth_corrected_median", "merged_remaining_bam", "merged_remaining_size", "depth_remaining_mean", "depth_remaining_sd", "depth_remaining_median", "total_reads_uncorrected", "total_reads_corrected", "total_reads_remaining", "ccs_success_wo_retry_generated", "ccs_success_w_retry_generated", "ccs_failed_below_snr_threshold", "ccs_failed_no_usable_subreads", "ccs_failed_insert_size_too_long", "ccs_failed_insert_size_too_small", "ccs_failed_not_enough_full_passes", "ccs_failed_too_many_unusable_subreads", "ccs_failed_did_not_converge", "ccs_failed_below_minimum_predicted_accuracy", "ccs_failed_unknown_error_during_processing")
tm = as_tibble(m)

tm$total_reads_uncorrected = as.integer(tm$total_reads_uncorrected)
tm$total_reads_corrected = as.integer(tm$total_reads_corrected)
tm$total_reads_remaining = as.integer(tm$total_reads_remaining)

tm$depth_uncorrected_median[is.na(tm$depth_uncorrected_median)] = 0
tm$depth_corrected_median[is.na(tm$depth_corrected_median)] = 0
tm$depth_remaining_median[is.na(tm$depth_remaining_median)] = 0

tm$codec = as.factor(tm$codec)
tm$compression = as.integer(tm$compression)
tm$shard_size = as.integer(tm$shard_size)
tm$run_type = as.factor(tm$run_type)

tm$merged_uncorrected_size = as.double(tm$merged_uncorrected_size)
tm$merged_corrected_size = as.double(tm$merged_corrected_size)
tm$merged_remaining_size = as.double(tm$merged_remaining_size)

tm$depth_uncorrected_mean = as.double(tm$depth_uncorrected_mean)
tm$depth_uncorrected_sd = as.double(tm$depth_uncorrected_sd)
tm$depth_uncorrected_median = as.double(tm$depth_uncorrected_median)

tm$depth_corrected_mean = as.double(tm$depth_corrected_mean)
tm$depth_corrected_sd = as.double(tm$depth_corrected_sd)
tm$depth_corrected_median = as.double(tm$depth_corrected_median)

tm$depth_remaining_mean = as.double(tm$depth_remaining_mean)
tm$depth_remaining_sd = as.double(tm$depth_remaining_sd)
tm$depth_remaining_median = as.double(tm$depth_remaining_median)

tm$ccs_success_wo_retry_generated = as.integer(tm$ccs_success_wo_retry_generated)
tm$ccs_success_w_retry_generated = as.integer(tm$ccs_success_w_retry_generated)
tm$ccs_failed_below_snr_threshold = as.integer(tm$ccs_failed_below_snr_threshold)
tm$ccs_failed_no_usable_subreads = as.integer(tm$ccs_failed_no_usable_subreads)
tm$ccs_failed_insert_size_too_long = as.integer(tm$ccs_failed_insert_size_too_long)
tm$ccs_failed_insert_size_too_small = as.integer(tm$ccs_failed_insert_size_too_small)
tm$ccs_failed_not_enough_full_passes = as.integer(tm$ccs_failed_not_enough_full_passes)
tm$ccs_failed_too_many_unusable_subreads = as.integer(tm$ccs_failed_too_many_unusable_subreads)
tm$ccs_failed_did_not_converge = as.integer(tm$ccs_failed_did_not_converge)
tm$ccs_failed_below_minimum_predicted_accuracy = as.integer(tm$ccs_failed_below_minimum_predicted_accuracy)
tm$ccs_failed_unknown_error_during_processing = as.integer(tm$ccs_failed_unknown_error_during_processing)
```

```{r latest_runs}
seen_runs = list()
selected_rows = c()

tm_desc = tm %>% arrange(desc(run_date))

for (i in 1:nrow(tm_desc)) {
    sn = tm_desc$sample_name[i]
    
    if (! sn %in% names(seen_runs)) {
        selected_rows = c(selected_rows, i)
    }
    
    seen_runs[sn] = 1
}

tm_sub = tm_desc[selected_rows,]
```

```{r error_rate}
d.uncorrected = read_delim("../../results/error_rate/all.uncorrected.txt", delim=" ");
d.uncorrected = inner_join(d.uncorrected, tm %>% select(cromwell_hash, sample_name)) %>% arrange(sample_name)
colnames(d.uncorrected) = c("cromwell_hash", "uncorrected_num_mismatches", "uncorrected_num_deletions", "uncorrected_num_insertions", "uncorrected_num_bases", "sample_name")

d.corrected = read_delim("../../results/error_rate/all.corrected.txt", delim=" ");
d.corrected = inner_join(d.corrected, tm %>% select(cromwell_hash, sample_name)) %>% arrange(sample_name)
colnames(d.corrected) = c("cromwell_hash", "corrected_num_mismatches", "corrected_num_deletions", "corrected_num_insertions", "corrected_num_bases", "sample_name")

d.uncorrected %<>% mutate(uncorrected_mismatch_rate = 100*uncorrected_num_mismatches/uncorrected_num_bases) %>%
                   mutate(uncorrected_deletion_rate = 100*uncorrected_num_deletions/uncorrected_num_bases) %>%
                   mutate(uncorrected_insertion_rate = 100*uncorrected_num_insertions/uncorrected_num_bases) %>%
                   mutate(uncorrected_error_rate = 100*((uncorrected_num_mismatches + uncorrected_num_deletions + uncorrected_num_insertions)/uncorrected_num_bases))

d.corrected %<>% mutate(corrected_mismatch_rate = 100*corrected_num_mismatches/corrected_num_bases) %>%
                   mutate(corrected_deletion_rate = 100*corrected_num_deletions/corrected_num_bases) %>%
                   mutate(corrected_insertion_rate = 100*corrected_num_insertions/corrected_num_bases) %>%
                   mutate(corrected_error_rate = 100*((corrected_num_mismatches + corrected_num_deletions + corrected_num_insertions)/corrected_num_bases))

dij = inner_join(
    d.uncorrected %>% select(sample_name, uncorrected_mismatch_rate, uncorrected_deletion_rate, uncorrected_insertion_rate, uncorrected_error_rate) %>% distinct(),
    d.corrected %>% select(sample_name, corrected_mismatch_rate, corrected_deletion_rate, corrected_insertion_rate, corrected_error_rate) %>% distinct()
)

dij %<>% filter(sample_name != "SmallTestData") %>% arrange(uncorrected_error_rate) %>% distinct()
dij = dij[2:nrow(dij),]
dij = dij[c(2, 3, 4, 5, 6, 8, 10, 11, 13), ]
dij[2, "sample_name"] = "NA12878"
dij %<>% arrange(sample_name)

da = tribble(
~mismatches, ~deletions, ~insertions, ~bases,
 0.7*85880573,    3927130,    2439225,     11702086109,
 0.7*88824450,    4372204,    2704999,     12964001414,
 0.7*94124921,    4673024,    2893108,     13913532449,
 0.7*116567038,   5504623,    3412812,     16450946868,
 0.7*6390020,     448212,     388683,      1123473038
)
da %<>% mutate(mm_rate = 100 * mismatches / bases, del_rate = 100 * deletions / bases, ins_rate = 100 * insertions / bases, tot_rate = 100 * (mismatches + deletions + insertions) / bases)

par(mar=c(8, 5, 2, 5))
plot(dij$uncorrected_error_rate, ylim=c(0.01, 300), bty="n", xaxt="n", xlab="", ylab="", pch=19, col="red", log="y", yaxt="n")
axis(2, at=c(0.01, 0.1, 1.0, 10.0, 100), labels=c(0.01, 0.1, 1.0, 10.0, 100.0), las=1)
mtext("Error rate (%)", 2, line=3, las=3)

points(dij$uncorrected_mismatch_rate, pch=4, col="red")
points(dij$uncorrected_insertion_rate, pch=2, col="red")
points(dij$uncorrected_deletion_rate, pch=6, col="red")
abline(h=mean(na.omit(dij$uncorrected_error_rate)), col="red", lty=2)
mtext(sprintf("%.2f%%", mean(na.omit(dij$uncorrected_error_rate))), 4, at=mean(na.omit(dij$uncorrected_error_rate)), las=2)
axis(1, at=1:nrow(dij), labels=dij$sample_name, las=2)
#legend("topleft", c("Total errors", "Insertion errors", "Deletion errors", "Mismatch errors"), pch=c(19, 2, 6, 4))

points(dij$corrected_error_rate, pch=19, col="blue")
points(dij$corrected_mismatch_rate, pch=4, col="blue")
points(dij$corrected_insertion_rate, pch=2, col="blue")
points(dij$corrected_deletion_rate, pch=6, col="blue")
abline(h=mean(na.omit(dij %>% filter(sample_name != "HG02982_CLR") %>% pull(corrected_error_rate))), col="blue", lty=2)
mtext(sprintf("%.2f%%", mean(na.omit(dij %>% filter(sample_name != "HG02982_CLR") %>% pull(corrected_error_rate)))), 4, at=mean(na.omit(dij %>% filter(sample_name != "HG02982_CLR") %>% pull(corrected_error_rate))), las=2)
axis(1, at=1:nrow(dij), labels=dij$sample_name, las=2)

#points(2.2, 100*(6390020+448212+388683)/1123473038, pch=4, cex=0.7, col="darkgreen")
#points(2.2, 100*6390020/1123473038, pch=4, cex=0.7, col="darkgreen")
#points(2.2, 100*448212/1123473038, pch=2, cex=0.7, col="darkgreen")
#points(2.2, 100*388683/1123473038, pch=6, cex=0.7, col="darkgreen")

points(rep(jitter(5.5, factor=1.3), nrow(da)), da$tot_rate, pch=19, cex=0.7, col="darkgreen")
points(rep(jitter(5.5, factor=1.3), nrow(da)), da$mm_rate, pch=4, cex=0.7, col="darkgreen")
points(rep(jitter(5.5, factor=1.3), nrow(da)), da$ins_rate, pch=2, cex=0.7, col="darkgreen")
points(rep(jitter(5.5, factor=1.3), nrow(da)), da$del_rate, pch=6, cex=0.7, col="darkgreen")
mtext("NA12878 HiSeqX/\nHiSeq2500 controls", 1, at=5.3, las=2, cex=0.7, padj=1, line=1.1)
abline(h=mean(da$tot_rate), col="darkgreen", lty=2)
mtext(sprintf("%.2f%%", mean(da$tot_rate)), 4, at=mean(da$tot_rate), las=2)

legend(1, 2e02, c("Total errors"), pch=19, bty="n", cex=0.8)
legend(3, 2e02, c("Insertion errors"), pch=2, bty="n", cex=0.8)
legend(5, 2e02, c("Deletion errors"), pch=6, bty="n", cex=0.8)
legend(7, 2e02, c("Mismatch errors"), pch=4, bty="n", cex=0.8)
```

```{r read_lengths, fig.width=2, fig.height=2}
rl_files = system("find ../../results/read_lengths -name '*.txt'", intern=TRUE)

p = FALSE
for (rl_file in rl_files) {
    mn = gsub(".subreads.ccs.aligned.merged.readlengths.txt", "", basename(rl_file))
    
    if (tm %>% filter(movie_name == mn, sample_name != "Ecoli_Training_Run", sample_name != "SmallTestData") %>% nrow() > 0) {
        #print(tm %>% filter(movie_name == mn))
        
        color = "red";
        linetype = 3;
        if (tm %>% filter(movie_name == mn) %>% pull(run_type) %>% unique() %in% ("CCS")) {
            color = "#00006677"
            linetype = 1;
        }
        
        d = read_delim(rl_file, delim=" ", col_names = c("zmw", "range", "length"))
        
        h = hist(d$length, breaks=seq(0, 300000, 100), plot=FALSE)
        
        #print(color)
        #print(mean(d$length))
        #print(median(d$length))
        
        if (p) {
            points(h$mids, h$density, type="l", lwd=2, col=color, lty=linetype)
        } else {
            plot(h$mids, h$density, type="l", lwd=2, xlim=c(0, 30000), ylim=c(0, 0.0010), bty="n", col=color, lty=linetype, xlab="Subread length (bp)", ylab="", xaxt="n", las=1)
            axis(1, at=c(0, 10000, 20000, 30000), cex.axis=1.3)
            p=TRUE
        }
    }
}

legend(15000, 7e-4, c("CCS", "CLR"), col=c("blue", "red"), lty=c(1, 2), lwd=2)
```

```{r read_length_hist}
h_clr = hist(rl_clr$length, breaks = seq(1,300000,by=1000), plot=FALSE)
h_ccs = hist(rl_ccs$length, breaks = seq(1,300000,by=1000), plot=FALSE)

plot(h_ccs$mids, h_ccs$density, type="l", xlim=c(0, 30000), lwd=2, col="blue", bty="n", xlab="Read length (bp)", ylab="Density", xaxt="n")
axis(1, at=c(0, 10000, 20000, 30000), cex.axis=1.3)
points(h_clr$mids, h_clr$density, type="l", xlim=c(0, 30000), lwd=2, col="red")
legend("topright", c("CCS", "CLR"), lwd=2, col=c("blue", "red"))
#abline(v=mean(rl_ccs$length), col="blue", lty=2)
abline(v=median(rl_ccs$length), col="blue", lty=2)
#mtext(as.integer(mean(rl_ccs$length)), 3, at=mean(rl_ccs$length))
mtext(as.integer(median(rl_ccs$length)), 3, at=median(rl_ccs$length))
#abline(v=mean(rl_clr$length), col="red", lty=2)
abline(v=(rl_clr %>% filter(length > 3000) %>% pull(length) %>% median()), col="red", lty=2)
#mtext(as.integer(mean(rl_clr$length)), 3, at=mean(rl_clr$length))
mtext(as.integer(rl_clr %>% filter(length > 3000) %>% pull(length) %>% median()), 3, at=rl_clr %>% filter(length > 3000) %>% pull(length) %>% median())

plot(h_clr$mids, h_clr$density, type="l", xlim=c(0, 50000), lwd=2, col="red", bty="n", xlab="Read length (bp)", ylab="Density")
legend("topright", c("CLR"), lwd=2, col=c("red"))
#abline(v=mean(rl_ccs$length), col="blue", lty=2)
abline(v=median(rl_ccs$length), col="blue", lty=2)
#mtext(as.integer(mean(rl_ccs$length)), 3, at=mean(rl_ccs$length))
mtext(as.integer(median(rl_ccs$length)), 3, at=median(rl_ccs$length))
#abline(v=mean(rl_clr$length), col="red", lty=2)
abline(v=median(rl_clr$length), col="red", lty=2)
#mtext(as.integer(mean(rl_clr$length)), 3, at=mean(rl_clr$length))
mtext(as.integer(median(rl_clr$length)), 3, at=median(rl_clr$length))
```

```{r costs}
ct_all = tibble()

for (costs_file in list.files("../../results/costs/", pattern="costs.txt", full.names=TRUE)) {
    if (file.info(costs_file)$size != 0) {
        ct = read_table(costs_file)
        ct_all = rbind(ct_all, ct)
    }
}

#cromwell_hash = tm_sub$cromwell_hash[1]
#for (cromwell_hash in tm_sub$cromwell_hash) {
#    costs_file = paste("../../results/costs/", cromwell_hash, ".costs.txt", sep="")
#    
#    if (!file.exists(costs_file)) {
#        print(paste("Costs for", cromwell_hash, " not computed yet"))
#    } else {
#        ct = read_table(costs_file)
#        ct$cromwell_hash = cromwell_hash
#        
#        ct_all = rbind(ct_all, ct)
#    }
#}

ct_all %<>% mutate(cromwell_hash = as_factor(cromwell_hash))
ct_all %<>% mutate(task_name = as_factor(task_name))
ct_all %<>% mutate(status = as_factor(status))
```

```{r costs_boxplot}
hashes.clr = tm_sub %>% filter(sample_name != "SmallTestData", sample_name != "Ecoli_Training_Run") %>% filter(grepl("CLR", sample_name)) %>% pull(cromwell_hash)
hashes.ccs = tm_sub %>% filter(sample_name != "SmallTestData", sample_name != "Ecoli_Training_Run") %>% filter(!grepl("CLR", sample_name)) %>% pull(cromwell_hash)

l = list(
    "SplitSubreads"       = ct_all %>% filter(status == "complete", task_name == "CorrectAndAlignWorkflow.SplitSubreads") %>% pull(total_cost),
    "CCS"                 = ct_all %>% filter(status == "complete", task_name == "CorrectAndAlignWorkflow.CCS") %>% pull(total_cost),
    "Minimap2Uncorrected" = ct_all %>% filter(status == "complete", task_name == "CorrectAndAlignWorkflow.Minimap2Uncorrected") %>% pull(total_cost),
    "Minimap2Corrected"   = ct_all %>% filter(status == "complete", task_name == "CorrectAndAlignWorkflow.Minimap2Corrected") %>% pull(total_cost),
    "MergeUncorrected"    = ct_all %>% filter(status == "complete", task_name == "CorrectAndAlignWorkflow.MergeUncorrected") %>% pull(total_cost),
    "MergeCorrected"      = ct_all %>% filter(status == "complete", task_name == "CorrectAndAlignWorkflow.MergeCorrected") %>% pull(total_cost),
    " " = c(),
    "Total (CLR)"         = ct_all %>% filter(status == "complete", cromwell_hash %in% hashes.clr) %>% group_by(cromwell_hash) %>% select(total_cost) %>% summarise(total_clr = sum(total_cost)) %>% pull(total_clr),
    "Total (CCS)"         = ct_all %>% filter(status == "complete", cromwell_hash %in% hashes.ccs) %>% group_by(cromwell_hash) %>% select(total_cost) %>% summarise(total_ccs = sum(total_cost)) %>% pull(total_ccs)
)

par(mar=c(11, 6, 4, 1))
b = boxplot(l, frame=FALSE, las=2, ylab="Cost ($)")
```

```{r coverage, fig.width=1.5, fig.height=1.5}
cov = list(
    corrected = c(15, 10, 10, 12, 10, 14, 10, 10, 12),
    uncorrected = c(200, 120, 140, 145, 117, 170, 195, 127, 133, 166)
)

par(mar=c(4, 6, 1, 1))
b = boxplot(cov, frame=FALSE, las=2, ylim=c(0, 200), xlab="Coverage", horizontal = TRUE)
abline(v = b$stats[3,1], col="red", lty=2)
mtext(sprintf("%.2fx", b$stats[3,1]), 3, at=b$stats[3,1])
abline(v = b$stats[3,2], col="red", lty=2)
mtext(sprintf("%.2fx", b$stats[3,2]), 3, at=b$stats[3,2])

#> m = sum(h$breaks[2:length(h$breaks)]*h$counts)/(sum(h$counts))
#> s = sqrt(sum(h$counts*((h$breaks[2:length(h$breaks)] - m)**2))/sum(h$counts))
#> m
#[1] 6.203183
#> s
#[1] 2.398369

```